{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/trialPromoResults.csv\")\n",
    "sex_map = {\"M\": 0, \"F\": 1}\n",
    "mstatus_map = {\"single\":0, \"married\":1, \"widowed\":2, \"divorced\":3}\n",
    "occupation_map = {'legal':0, 'IT':1, 'government':2, 'manuf':3, 'retired':4, \n",
    "                  'finance':5,'construct':6, 'education':7, 'medicine':8}\n",
    "education_map = {'postgrad':3, 'secondary':0, 'tertiary':1, 'professional':2}\n",
    "decision_map = {\"A\":0, \"B\":1, \"None\":2}\n",
    "df[\"sex\"] = df[\"sex\"].map(sex_map)\n",
    "df[\"mstatus\"] = df[\"mstatus\"].map(mstatus_map)\n",
    "df[\"occupation\"] = df[\"occupation\"].map(occupation_map)\n",
    "df[\"education\"] = df[\"education\"].map(education_map)\n",
    "df[\"decision\"] = df[\"decision\"].map(decision_map)\n",
    "df = pd.get_dummies(df, columns=[\"sex\",\"mstatus\",\"occupation\",\"education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[list(set(df.columns) - set([\"index\", \"decision\"]))]\n",
    "y = df[\"decision\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3)\n",
    "normalizer = preprocessing.Normalizer()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 200), (1, 200), (2, 580)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = RandomOverSampler(ratio={0:200, 1:200}).fit_sample(X_train, y_train)\n",
    "# X_resampled, y_resampled = RandomUnderSampler(ratio={2:250}).fit_sample(X_resampled, y_resampled)\n",
    "X_train = X_resampled\n",
    "y_train = y_resampled\n",
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "dummy_y = np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_metrics(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "980/980 [==============================] - 1s 795us/step - loss: 0.6028 - precision_metrics: 0.0000e+00\n",
      "Epoch 2/150\n",
      "980/980 [==============================] - 0s 406us/step - loss: 0.5760 - precision_metrics: 0.2828\n",
      "Epoch 3/150\n",
      "980/980 [==============================] - 0s 434us/step - loss: 0.5642 - precision_metrics: 0.5901\n",
      "Epoch 4/150\n",
      "980/980 [==============================] - 0s 391us/step - loss: 0.5622 - precision_metrics: 0.5918\n",
      "Epoch 5/150\n",
      "980/980 [==============================] - 0s 408us/step - loss: 0.5616 - precision_metrics: 0.5918\n",
      "Epoch 6/150\n",
      "980/980 [==============================] - 0s 405us/step - loss: 0.5611 - precision_metrics: 0.5918\n",
      "Epoch 7/150\n",
      "980/980 [==============================] - 0s 388us/step - loss: 0.5608 - precision_metrics: 0.5918\n",
      "Epoch 8/150\n",
      "980/980 [==============================] - 0s 428us/step - loss: 0.5608 - precision_metrics: 0.5918\n",
      "Epoch 9/150\n",
      "980/980 [==============================] - 0s 432us/step - loss: 0.5602 - precision_metrics: 0.5918\n",
      "Epoch 10/150\n",
      "980/980 [==============================] - 0s 414us/step - loss: 0.5599 - precision_metrics: 0.5918\n",
      "Epoch 11/150\n",
      "980/980 [==============================] - 0s 395us/step - loss: 0.5601 - precision_metrics: 0.5918\n",
      "Epoch 12/150\n",
      "980/980 [==============================] - 0s 397us/step - loss: 0.5596 - precision_metrics: 0.5918\n",
      "Epoch 13/150\n",
      "980/980 [==============================] - 0s 408us/step - loss: 0.5590 - precision_metrics: 0.5918\n",
      "Epoch 14/150\n",
      "980/980 [==============================] - 0s 402us/step - loss: 0.5590 - precision_metrics: 0.5918\n",
      "Epoch 15/150\n",
      "980/980 [==============================] - 0s 388us/step - loss: 0.5590 - precision_metrics: 0.5918\n",
      "Epoch 16/150\n",
      "980/980 [==============================] - 0s 396us/step - loss: 0.5587 - precision_metrics: 0.5918\n",
      "Epoch 17/150\n",
      "980/980 [==============================] - 0s 391us/step - loss: 0.5582 - precision_metrics: 0.5918\n",
      "Epoch 18/150\n",
      "980/980 [==============================] - 0s 388us/step - loss: 0.5579 - precision_metrics: 0.5918\n",
      "Epoch 19/150\n",
      "980/980 [==============================] - 0s 400us/step - loss: 0.5579 - precision_metrics: 0.5918\n",
      "Epoch 20/150\n",
      "980/980 [==============================] - 0s 413us/step - loss: 0.5573 - precision_metrics: 0.5918\n",
      "Epoch 21/150\n",
      "980/980 [==============================] - 0s 414us/step - loss: 0.5571 - precision_metrics: 0.5918\n",
      "Epoch 22/150\n",
      "980/980 [==============================] - 0s 395us/step - loss: 0.5567 - precision_metrics: 0.5918\n",
      "Epoch 23/150\n",
      "980/980 [==============================] - 0s 403us/step - loss: 0.5562 - precision_metrics: 0.5918\n",
      "Epoch 24/150\n",
      "980/980 [==============================] - 0s 400us/step - loss: 0.5562 - precision_metrics: 0.5918\n",
      "Epoch 25/150\n",
      "980/980 [==============================] - 0s 403us/step - loss: 0.5558 - precision_metrics: 0.5918\n",
      "Epoch 26/150\n",
      "980/980 [==============================] - 0s 394us/step - loss: 0.5553 - precision_metrics: 0.5918\n",
      "Epoch 27/150\n",
      "980/980 [==============================] - 0s 388us/step - loss: 0.5547 - precision_metrics: 0.5918\n",
      "Epoch 28/150\n",
      "980/980 [==============================] - 0s 384us/step - loss: 0.5546 - precision_metrics: 0.5918\n",
      "Epoch 29/150\n",
      "980/980 [==============================] - 0s 409us/step - loss: 0.5541 - precision_metrics: 0.5918\n",
      "Epoch 30/150\n",
      "980/980 [==============================] - 0s 404us/step - loss: 0.5541 - precision_metrics: 0.5918\n",
      "Epoch 31/150\n",
      "980/980 [==============================] - 0s 389us/step - loss: 0.5534 - precision_metrics: 0.5918\n",
      "Epoch 32/150\n",
      "980/980 [==============================] - 0s 384us/step - loss: 0.5529 - precision_metrics: 0.5918\n",
      "Epoch 33/150\n",
      "980/980 [==============================] - 0s 398us/step - loss: 0.5528 - precision_metrics: 0.5918\n",
      "Epoch 34/150\n",
      "980/980 [==============================] - 0s 405us/step - loss: 0.5525 - precision_metrics: 0.5918\n",
      "Epoch 35/150\n",
      "980/980 [==============================] - 0s 408us/step - loss: 0.5518 - precision_metrics: 0.5918\n",
      "Epoch 36/150\n",
      "980/980 [==============================] - 0s 379us/step - loss: 0.5516 - precision_metrics: 0.5918\n",
      "Epoch 37/150\n",
      "980/980 [==============================] - 0s 392us/step - loss: 0.5512 - precision_metrics: 0.5928\n",
      "Epoch 38/150\n",
      "980/980 [==============================] - 0s 390us/step - loss: 0.5509 - precision_metrics: 0.5918\n",
      "Epoch 39/150\n",
      "980/980 [==============================] - 0s 392us/step - loss: 0.5510 - precision_metrics: 0.5949\n",
      "Epoch 40/150\n",
      "980/980 [==============================] - 0s 397us/step - loss: 0.5504 - precision_metrics: 0.5928\n",
      "Epoch 41/150\n",
      "980/980 [==============================] - 0s 414us/step - loss: 0.5501 - precision_metrics: 0.5973\n",
      "Epoch 42/150\n",
      "980/980 [==============================] - 0s 411us/step - loss: 0.5503 - precision_metrics: 0.5950\n",
      "Epoch 43/150\n",
      "980/980 [==============================] - 0s 379us/step - loss: 0.5500 - precision_metrics: 0.5912\n",
      "Epoch 44/150\n",
      "980/980 [==============================] - 0s 393us/step - loss: 0.5495 - precision_metrics: 0.5951\n",
      "Epoch 45/150\n",
      "980/980 [==============================] - 0s 394us/step - loss: 0.5492 - precision_metrics: 0.5961\n",
      "Epoch 46/150\n",
      "980/980 [==============================] - 0s 403us/step - loss: 0.5487 - precision_metrics: 0.5999\n",
      "Epoch 47/150\n",
      "980/980 [==============================] - 0s 391us/step - loss: 0.5485 - precision_metrics: 0.6022\n",
      "Epoch 48/150\n",
      "980/980 [==============================] - 0s 396us/step - loss: 0.5492 - precision_metrics: 0.5982\n",
      "Epoch 49/150\n",
      "980/980 [==============================] - 0s 403us/step - loss: 0.5480 - precision_metrics: 0.6073\n",
      "Epoch 50/150\n",
      "980/980 [==============================] - 0s 411us/step - loss: 0.5478 - precision_metrics: 0.6043\n",
      "Epoch 51/150\n",
      "980/980 [==============================] - 0s 405us/step - loss: 0.5477 - precision_metrics: 0.6048\n",
      "Epoch 52/150\n",
      "980/980 [==============================] - 0s 411us/step - loss: 0.5474 - precision_metrics: 0.6024\n",
      "Epoch 53/150\n",
      "980/980 [==============================] - 0s 414us/step - loss: 0.5479 - precision_metrics: 0.6062\n",
      "Epoch 54/150\n",
      "980/980 [==============================] - 0s 437us/step - loss: 0.5475 - precision_metrics: 0.6102\n",
      "Epoch 55/150\n",
      "980/980 [==============================] - 0s 416us/step - loss: 0.5472 - precision_metrics: 0.6043\n",
      "Epoch 56/150\n",
      "980/980 [==============================] - 0s 413us/step - loss: 0.5471 - precision_metrics: 0.6106\n",
      "Epoch 57/150\n",
      "980/980 [==============================] - 0s 421us/step - loss: 0.5469 - precision_metrics: 0.6088\n",
      "Epoch 58/150\n",
      "980/980 [==============================] - 0s 395us/step - loss: 0.5466 - precision_metrics: 0.6103\n",
      "Epoch 59/150\n",
      "980/980 [==============================] - 0s 415us/step - loss: 0.5468 - precision_metrics: 0.6097\n",
      "Epoch 60/150\n",
      "980/980 [==============================] - 0s 445us/step - loss: 0.5466 - precision_metrics: 0.6101\n",
      "Epoch 61/150\n",
      "980/980 [==============================] - 0s 475us/step - loss: 0.5464 - precision_metrics: 0.6095\n",
      "Epoch 62/150\n",
      "980/980 [==============================] - 1s 683us/step - loss: 0.5464 - precision_metrics: 0.6125\n",
      "Epoch 63/150\n",
      "980/980 [==============================] - 0s 506us/step - loss: 0.5463 - precision_metrics: 0.6127\n",
      "Epoch 64/150\n",
      "980/980 [==============================] - 0s 485us/step - loss: 0.5459 - precision_metrics: 0.6097\n",
      "Epoch 65/150\n",
      "980/980 [==============================] - 0s 431us/step - loss: 0.5460 - precision_metrics: 0.6076\n",
      "Epoch 66/150\n",
      "980/980 [==============================] - 1s 516us/step - loss: 0.5459 - precision_metrics: 0.6083\n",
      "Epoch 67/150\n",
      "980/980 [==============================] - 1s 533us/step - loss: 0.5456 - precision_metrics: 0.6102 0s - loss: 0.5554 - precision_metrics:\n",
      "Epoch 68/150\n",
      "980/980 [==============================] - 1s 606us/step - loss: 0.5457 - precision_metrics: 0.6126\n",
      "Epoch 69/150\n",
      "980/980 [==============================] - ETA: 0s - loss: 0.5458 - precision_metrics: 0.607 - 0s 502us/step - loss: 0.5454 - precision_metrics: 0.6098\n",
      "Epoch 70/150\n",
      "980/980 [==============================] - 0s 463us/step - loss: 0.5458 - precision_metrics: 0.6071\n",
      "Epoch 71/150\n",
      "980/980 [==============================] - 0s 501us/step - loss: 0.5457 - precision_metrics: 0.6114 0s - loss: 0.5335 - precision_metrics\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 0s 452us/step - loss: 0.5464 - precision_metrics: 0.6090\n",
      "Epoch 73/150\n",
      "980/980 [==============================] - 0s 395us/step - loss: 0.5455 - precision_metrics: 0.6096\n",
      "Epoch 74/150\n",
      "980/980 [==============================] - 0s 412us/step - loss: 0.5454 - precision_metrics: 0.6110\n",
      "Epoch 75/150\n",
      "980/980 [==============================] - 0s 414us/step - loss: 0.5456 - precision_metrics: 0.6147\n",
      "Epoch 76/150\n",
      "980/980 [==============================] - 0s 411us/step - loss: 0.5456 - precision_metrics: 0.6166\n",
      "Epoch 77/150\n",
      "980/980 [==============================] - 0s 381us/step - loss: 0.5454 - precision_metrics: 0.6108\n",
      "Epoch 78/150\n",
      "980/980 [==============================] - 0s 416us/step - loss: 0.5447 - precision_metrics: 0.6102\n",
      "Epoch 79/150\n",
      "980/980 [==============================] - 0s 398us/step - loss: 0.5455 - precision_metrics: 0.6091\n",
      "Epoch 80/150\n",
      "980/980 [==============================] - 0s 423us/step - loss: 0.5449 - precision_metrics: 0.6141\n",
      "Epoch 81/150\n",
      "980/980 [==============================] - 0s 418us/step - loss: 0.5448 - precision_metrics: 0.6101\n",
      "Epoch 82/150\n",
      "980/980 [==============================] - 0s 433us/step - loss: 0.5452 - precision_metrics: 0.6094\n",
      "Epoch 83/150\n",
      "980/980 [==============================] - 0s 412us/step - loss: 0.5448 - precision_metrics: 0.6104\n",
      "Epoch 84/150\n",
      "980/980 [==============================] - 0s 442us/step - loss: 0.5444 - precision_metrics: 0.6070\n",
      "Epoch 85/150\n",
      "980/980 [==============================] - 0s 427us/step - loss: 0.5446 - precision_metrics: 0.6083\n",
      "Epoch 86/150\n",
      "980/980 [==============================] - 0s 395us/step - loss: 0.5443 - precision_metrics: 0.6092\n",
      "Epoch 87/150\n",
      "980/980 [==============================] - 0s 429us/step - loss: 0.5443 - precision_metrics: 0.6048\n",
      "Epoch 88/150\n",
      "980/980 [==============================] - 0s 418us/step - loss: 0.5441 - precision_metrics: 0.6074\n",
      "Epoch 89/150\n",
      "980/980 [==============================] - 0s 399us/step - loss: 0.5443 - precision_metrics: 0.6098\n",
      "Epoch 90/150\n",
      "980/980 [==============================] - 0s 415us/step - loss: 0.5438 - precision_metrics: 0.6089\n",
      "Epoch 91/150\n",
      "980/980 [==============================] - 0s 402us/step - loss: 0.5441 - precision_metrics: 0.6090\n",
      "Epoch 92/150\n",
      "980/980 [==============================] - 0s 444us/step - loss: 0.5441 - precision_metrics: 0.6083\n",
      "Epoch 93/150\n",
      "980/980 [==============================] - 0s 426us/step - loss: 0.5441 - precision_metrics: 0.6140\n",
      "Epoch 94/150\n",
      "980/980 [==============================] - 0s 418us/step - loss: 0.5440 - precision_metrics: 0.6112\n",
      "Epoch 95/150\n",
      "980/980 [==============================] - 0s 440us/step - loss: 0.5439 - precision_metrics: 0.6103\n",
      "Epoch 96/150\n",
      "980/980 [==============================] - 0s 413us/step - loss: 0.5444 - precision_metrics: 0.6061\n",
      "Epoch 97/150\n",
      "980/980 [==============================] - 0s 430us/step - loss: 0.5439 - precision_metrics: 0.6105\n",
      "Epoch 98/150\n",
      "980/980 [==============================] - 0s 397us/step - loss: 0.5438 - precision_metrics: 0.6127\n",
      "Epoch 99/150\n",
      "980/980 [==============================] - 0s 401us/step - loss: 0.5433 - precision_metrics: 0.6104\n",
      "Epoch 100/150\n",
      "980/980 [==============================] - 0s 400us/step - loss: 0.5435 - precision_metrics: 0.6107\n",
      "Epoch 101/150\n",
      "980/980 [==============================] - 0s 416us/step - loss: 0.5436 - precision_metrics: 0.6048\n",
      "Epoch 102/150\n",
      "980/980 [==============================] - 0s 414us/step - loss: 0.5434 - precision_metrics: 0.6093\n",
      "Epoch 103/150\n",
      "980/980 [==============================] - 0s 418us/step - loss: 0.5439 - precision_metrics: 0.6124\n",
      "Epoch 104/150\n",
      "980/980 [==============================] - 0s 416us/step - loss: 0.5434 - precision_metrics: 0.6084\n",
      "Epoch 105/150\n",
      "980/980 [==============================] - 0s 418us/step - loss: 0.5435 - precision_metrics: 0.6195\n",
      "Epoch 106/150\n",
      "980/980 [==============================] - 0s 423us/step - loss: 0.5436 - precision_metrics: 0.6118\n",
      "Epoch 107/150\n",
      "980/980 [==============================] - 0s 414us/step - loss: 0.5436 - precision_metrics: 0.6123\n",
      "Epoch 108/150\n",
      "980/980 [==============================] - 0s 420us/step - loss: 0.5435 - precision_metrics: 0.6093\n",
      "Epoch 109/150\n",
      "980/980 [==============================] - 0s 417us/step - loss: 0.5432 - precision_metrics: 0.6118\n",
      "Epoch 110/150\n",
      "980/980 [==============================] - 0s 447us/step - loss: 0.5429 - precision_metrics: 0.6141\n",
      "Epoch 111/150\n",
      "980/980 [==============================] - 0s 400us/step - loss: 0.5430 - precision_metrics: 0.6123\n",
      "Epoch 112/150\n",
      "980/980 [==============================] - 0s 420us/step - loss: 0.5430 - precision_metrics: 0.6124\n",
      "Epoch 113/150\n",
      "980/980 [==============================] - 0s 445us/step - loss: 0.5429 - precision_metrics: 0.6123\n",
      "Epoch 114/150\n",
      "980/980 [==============================] - 0s 426us/step - loss: 0.5434 - precision_metrics: 0.6123\n",
      "Epoch 115/150\n",
      "980/980 [==============================] - 0s 442us/step - loss: 0.5431 - precision_metrics: 0.6126\n",
      "Epoch 116/150\n",
      "980/980 [==============================] - 0s 421us/step - loss: 0.5427 - precision_metrics: 0.6114\n",
      "Epoch 117/150\n",
      "980/980 [==============================] - 0s 449us/step - loss: 0.5428 - precision_metrics: 0.6141\n",
      "Epoch 118/150\n",
      "980/980 [==============================] - 0s 425us/step - loss: 0.5428 - precision_metrics: 0.6090\n",
      "Epoch 119/150\n",
      "980/980 [==============================] - 0s 442us/step - loss: 0.5426 - precision_metrics: 0.6107\n",
      "Epoch 120/150\n",
      "980/980 [==============================] - 0s 421us/step - loss: 0.5429 - precision_metrics: 0.6094\n",
      "Epoch 121/150\n",
      "980/980 [==============================] - 0s 450us/step - loss: 0.5433 - precision_metrics: 0.6111\n",
      "Epoch 122/150\n",
      "980/980 [==============================] - 0s 436us/step - loss: 0.5427 - precision_metrics: 0.6090\n",
      "Epoch 123/150\n",
      "980/980 [==============================] - 0s 425us/step - loss: 0.5425 - precision_metrics: 0.6143\n",
      "Epoch 124/150\n",
      "980/980 [==============================] - 0s 433us/step - loss: 0.5425 - precision_metrics: 0.6078\n",
      "Epoch 125/150\n",
      "980/980 [==============================] - 0s 432us/step - loss: 0.5430 - precision_metrics: 0.6146\n",
      "Epoch 126/150\n",
      "980/980 [==============================] - 0s 411us/step - loss: 0.5420 - precision_metrics: 0.6137\n",
      "Epoch 127/150\n",
      "980/980 [==============================] - 0s 411us/step - loss: 0.5424 - precision_metrics: 0.6099\n",
      "Epoch 128/150\n",
      "980/980 [==============================] - 0s 433us/step - loss: 0.5429 - precision_metrics: 0.6129\n",
      "Epoch 129/150\n",
      "980/980 [==============================] - 0s 417us/step - loss: 0.5421 - precision_metrics: 0.6083\n",
      "Epoch 130/150\n",
      "980/980 [==============================] - 0s 426us/step - loss: 0.5419 - precision_metrics: 0.6114\n",
      "Epoch 131/150\n",
      "980/980 [==============================] - 0s 451us/step - loss: 0.5419 - precision_metrics: 0.6083\n",
      "Epoch 132/150\n",
      "980/980 [==============================] - 0s 416us/step - loss: 0.5421 - precision_metrics: 0.6071\n",
      "Epoch 133/150\n",
      "980/980 [==============================] - 0s 437us/step - loss: 0.5419 - precision_metrics: 0.6146\n",
      "Epoch 134/150\n",
      "980/980 [==============================] - 0s 405us/step - loss: 0.5417 - precision_metrics: 0.6206\n",
      "Epoch 135/150\n",
      "980/980 [==============================] - 0s 421us/step - loss: 0.5418 - precision_metrics: 0.6157\n",
      "Epoch 136/150\n",
      "980/980 [==============================] - 0s 407us/step - loss: 0.5413 - precision_metrics: 0.6161\n",
      "Epoch 137/150\n",
      "980/980 [==============================] - 0s 437us/step - loss: 0.5413 - precision_metrics: 0.6211\n",
      "Epoch 138/150\n",
      "980/980 [==============================] - 0s 419us/step - loss: 0.5412 - precision_metrics: 0.6152\n",
      "Epoch 139/150\n",
      "980/980 [==============================] - 0s 424us/step - loss: 0.5417 - precision_metrics: 0.6179\n",
      "Epoch 140/150\n",
      "980/980 [==============================] - 0s 429us/step - loss: 0.5412 - precision_metrics: 0.6223\n",
      "Epoch 141/150\n",
      "980/980 [==============================] - 0s 412us/step - loss: 0.5416 - precision_metrics: 0.6224\n",
      "Epoch 142/150\n",
      "980/980 [==============================] - 0s 437us/step - loss: 0.5414 - precision_metrics: 0.6168\n",
      "Epoch 143/150\n",
      "980/980 [==============================] - 0s 417us/step - loss: 0.5408 - precision_metrics: 0.6123\n",
      "Epoch 144/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 0s 401us/step - loss: 0.5406 - precision_metrics: 0.6212\n",
      "Epoch 145/150\n",
      "980/980 [==============================] - 0s 381us/step - loss: 0.5406 - precision_metrics: 0.6148\n",
      "Epoch 146/150\n",
      "980/980 [==============================] - 0s 375us/step - loss: 0.5411 - precision_metrics: 0.6130\n",
      "Epoch 147/150\n",
      "980/980 [==============================] - 0s 393us/step - loss: 0.5406 - precision_metrics: 0.6193\n",
      "Epoch 148/150\n",
      "980/980 [==============================] - 0s 377us/step - loss: 0.5405 - precision_metrics: 0.6196\n",
      "Epoch 149/150\n",
      "980/980 [==============================] - 0s 375us/step - loss: 0.5404 - precision_metrics: 0.6151\n",
      "Epoch 150/150\n",
      "980/980 [==============================] - 0s 373us/step - loss: 0.5398 - precision_metrics: 0.6153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1883cf160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import metrics as kmetrics\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision_metrics])\n",
    "model.fit(X_train, dummy_y, epochs=150, batch_size=20, class_weight=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "[[  5   2 193]\n",
      " [  0  13 187]\n",
      " [  0   1 579]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.03      0.05       200\n",
      "          1       0.81      0.07      0.12       200\n",
      "          2       0.60      1.00      0.75       580\n",
      "\n",
      "avg / total       0.73      0.61      0.48       980\n",
      "\n",
      "0.6091836734693877\n",
      "Test set\n",
      "[[  0   1  39]\n",
      " [  0   0  12]\n",
      " [  0   0 248]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        40\n",
      "          1       0.00      0.00      0.00        12\n",
      "          2       0.83      1.00      0.91       248\n",
      "\n",
      "avg / total       0.69      0.83      0.75       300\n",
      "\n",
      "0.8266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\siddp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set\")\n",
    "y_pred = model.predict(X_train).squeeze()\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "print(metrics.confusion_matrix(y_train, y_pred))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "print(metrics.accuracy_score(y_train, y_pred))\n",
    "print(\"Test set\")\n",
    "y_pred = model.predict(X_test).squeeze()\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
